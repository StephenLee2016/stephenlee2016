---
layout:     post
title:      FastText 文本分类
subtitle:   又快又好用的文本分类模型
date:       2017-08-25
author:     Stephen
header-img: img/home-bg-art.jpg
tags:
    - FastText
    - Text Classification
    - 文本分类
---

# FastText 文本分类

---

> 前段时间，使用CNN进行文本分类，最终取得了不错的效果。但是训练时间在我没有gpu的小破笔记本上实在是等的花都谢了。于是尝试了Word2Vec作者、Facebook科学家Mikolov开源的FastTex方法，效果真是谁用谁知道，一般人我真不告诉他！

---

## FastText 原理

### 模型架构

FastText 是一种有监督的模型，基础结构如下图。

![fasttext structure](http://www.kejik.com/image/1471094584474.png)

但看模型的架构，似乎和 word2vec 中的 cbow 模型很像啊！

![skip-gram](http://img.blog.csdn.net/20160718160400537)

开始我看到结构图也是觉得，这不就是一样的嘛！但是...但是...但是还是有很大的区别的，简单点说有下面几处不同：

- 1、FastText 是一个监督学习， cbow 是一个非监督学习。
- 2、cbow 是用一个词窗口内的其他词来预测这个词，FastText 是一句话来预测这句话的类别。
- 3、FastText 中的训练样本使用的是bag of words思想，加入了数据的n-gram属性。而cbow则要求训练数据的有序性。

---

好了，清楚了 FastText 的基础结构，就来看看为什么 FastText 会有如此优秀的性能。

---

### 层次 Softmax

FastText 和 CBow 都用到了层次化的 Softmax， 具体的介绍看[这篇文章][1]。

---

### N-gram 特征

FastText 可以用于文本分类和句子分类。不管是文本分类还是句子分类，我们常用的特征是词袋模型。但词袋模型不能考虑词之间的顺序，因此 FastText 还加入了 N-gram 特征。“我 爱 她” 这句话中的词袋模型特征是 “我”，“爱”, “她”。这些特征和句子 “她 爱 我” 的特征是一样的。如果加入 2-Ngram，第一句话的特征还有 “我-爱” 和 “爱-她”，这两句话 “我 爱 她” 和 “她 爱 我” 就能区别开来了。当然啦，为了提高效率，我们需要过滤掉低频的 N-gram。

---

## FastText 应用

在我们的业务中，需要将文本数据分成122类，总共8w多的样本量，最多的类别有4000多条，最少的只有两位数，最终用FastText训练的时间一分钟左右，比CNN快了不知多少倍。最终的分类准确率可以达到接近90%。

我这里放一张分类的图形化混淆矩阵图片，大家可以看一下各类的准确率。

![confusion-matrix](http://mt1.baidu.com/timg?shitu&quality=100&sharpen=100&er=&imgtype=0&wh_rate=null&size=h120&sec=1503652297&di=b012c40ecf811c481c0536fe8f80c768&src=http%3A%2F%2Fe.hiphotos.baidu.com%2Fimage%2F%2570%2569%2563%2Fitem%2Fd058ccbf6c81800ab56349ccbb3533fa838b476a.jpg)

整体还是不错的，目前模型已经上线，表现不错。

[1]:http://www.cnblogs.com/Jezze/archive/2011/12/23/2299884.html